{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CpGs Detector\n",
    "\n",
    "Here we have a simple problem, given a DNA sequence (of N, A, C, G, T), count the number of CpGs in the sequence (consecutive CGs).\n",
    "\n",
    "We have defined a few helper functions / parameters for performing this task.\n",
    "\n",
    "We need you to build a LSTM model and train it to complish this task in PyTorch.\n",
    "\n",
    "A good solution will be a model that can be trained, with high confidence in correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Sequence\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=13):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence(n_seqs: int, seq_len: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        yield [random.randint(0, 4) for _ in range(seq_len)]\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "# Alphabet helpers\n",
    "alphabet = 'NACGT'\n",
    "dna2int = { a: i for a, i in zip(alphabet, range(5))}\n",
    "int2dna = { i: a for a, i in zip(alphabet, range(5))}\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we prepared two datasets for training and evaluation\n",
    "# training data scale we set to 2048\n",
    "# we test on 512\n",
    "\n",
    "def prepare_data(num_samples=100):\n",
    "    # prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    # step 1\n",
    "    X_dna_seqs_train = list(rand_sequence(num_samples))\n",
    "    temp =  [list(intseq_to_dnaseq(i)) for i in X_dna_seqs_train] #\n",
    "    y_dna_seqs =  [count_cpgs(\"\".join(i)) for i in temp]\n",
    "    return X_dna_seqs_train, y_dna_seqs\n",
    "\n",
    "train_x, train_y = prepare_data(2048)\n",
    "test_x, test_y = prepare_data(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def convert_to_tensor(data, dtype=torch.long):\n",
    "    return torch.tensor(data, dtype=dtype)\n",
    "\n",
    "train_x_tensor = convert_to_tensor(train_x)\n",
    "train_y_tensor = convert_to_tensor(train_y)\n",
    "test_x_tensor = convert_to_tensor(test_x)\n",
    "test_y_tensor = convert_to_tensor(test_y)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGPredictor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob=0.5):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(5, input_dim)\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.classifier = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        logits = self.classifier(lstm_out)\n",
    "        return logits\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "input_dim = 128\n",
    "hidden_dim = 128\n",
    "layer_dim = 1\n",
    "output_dim = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "## Check if gpu is available\n",
    "cuda_or_cpu = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(cuda_or_cpu)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = CpGPredictor(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.to(device) # Transfer the model to GPU/CPU\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 6.772491931915283\n",
      "Epoch 2/10, Loss: 4.583024978637695\n",
      "Epoch 3/10, Loss: 3.4164929389953613\n",
      "Epoch 4/10, Loss: 4.15935754776001\n",
      "Epoch 5/10, Loss: 3.899125099182129\n",
      "Epoch 6/10, Loss: 1.675019383430481\n",
      "Epoch 7/10, Loss: 0.2483929544687271\n",
      "Epoch 8/10, Loss: 0.8165625333786011\n",
      "Epoch 9/10, Loss: 0.3686717450618744\n",
      "Epoch 10/10, Loss: 0.2534410357475281\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_data_loader, loss_fn, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")     \n",
    "\n",
    "train_model(model, train_data_loader, loss_fn, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss on test data: 4.090817257761955\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_data_loader, loss_fn):\n",
    "    total_loss = 0\n",
    "    for inputs, labels in test_data_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), labels.float())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss/len(test_data_loader)\n",
    "    print(f\"Average loss on test data: {avg_loss}\")\n",
    "\n",
    "test_dataset = TensorDataset(test_x_tensor, test_y_tensor)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "evaluate_model(model, test_data_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: NCACANNTNCGGAGGCGNANCACANNTNCGGAGGCGNA, Predicted CpGs: 5, Actual CpGs: 4\n",
      "Sequence: NCACANNTNCGGAGGCGCGNCACANNTNCGGAGGCGCG, Predicted CpGs: 6, Actual CpGs: 6\n"
     ]
    }
   ],
   "source": [
    "# Testing wth examples (Should be of te same size)\n",
    "# To use examples of different size, we need to use padding\n",
    "\n",
    "examples = [\"NCACANNTNCGGAGGCGNANCACANNTNCGGAGGCGNA\", \"NCACANNTNCGGAGGCGCGNCACANNTNCGGAGGCGCG\"]\n",
    "\n",
    "def get_actual_count(examples):\n",
    "  return [count_cpgs(\"\".join(i)) for i in examples]\n",
    "\n",
    "def encode_to_integer(examples):\n",
    "  int_sequence = [list(dnaseq_to_intseq(i)) for i in examples]\n",
    "  return int_sequence\n",
    "\n",
    "def transform_examples(data):\n",
    "  int_sequence = encode_to_integer(data)\n",
    "  test_sequnce = convert_to_tensor(int_sequence)\n",
    "  return test_sequnce\n",
    "\n",
    "def predict(model, unseen_data):\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = transform_examples(unseen_data)\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    predictions = outputs.squeeze().cpu().numpy()\n",
    "  return predictions\n",
    "\n",
    "predictions = predict(model, examples)\n",
    "actual_vals = get_actual_count(examples)\n",
    "\n",
    "for i in range(len(examples)):\n",
    "  print(f\"Sequence: {examples[i]}, Predicted CpGs: {round(predictions[i])}, Actual CpGs: {actual_vals[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('my_torch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecbdff7fd6760a586c96ed51051ada5a57f6dcd1426975f25013dd3c7741d2ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
